# Summary of Hannah Fry â€” The Knowledge Project #87

Source: https://youtube.com/watch?v=2vEuh54f3S4

Mathematician Hannah Fry discusses how math can be made more engaging and relatable to students by humanizing the stories behind it, such as the emotional element in Formula One racing. She also warns of the dangers of blindly trusting algorithms without considering human context, citing examples like faulty GPS and over-diagnosis in medical algorithms. Fry suggests potential solutions for algorithm transparency, such as a separate regulatory board for stress-testing and verifying them, and emphasizes the importance of involving humans in the decision-making process. Finally, Fry applies math to understanding human relationships, showcasing how low negativity thresholds can lead to successful long-term couples by resolving small issues before they escalate.

Detail Summary: 
00:00:00
In this section, math professor Hannah Fry discusses her personal interest in math and how schools can promote better engagement with students. She mentions the importance of demonstrating how mathematics is useful in various aspects of modern society to make the subject come alive for students. While algorithms and machines surround kids today, Fry notes that the math behind these technologies is often invisible to users. Additionally, she challenges the idea of celebrating engineers instead of drivers in racing, arguing that it's important to celebrate both in order to get kids interested in the work.

00:05:00
In this section of the video, mathematician and author Hannah Fry discusses the importance of humanizing math and algorithms. She explains that making the stories about the people involved, similar to the way Formula One racing adds an emotional element to the technological advancements of the engineered machines, can make math more engaging and relatable. Fry also notes the necessity of humanizing the math itself to ensure it fits into our society and avoids the catastrophic consequences of rushing ahead without considering the biases that can be built into algorithms.

00:10:00
In this section, Hannah Fry shares a personal story about the dangers of blindly trusting algorithms and not considering human context. In 2011, she worked with the Metropolitan Police in London to identify patterns in the data during the riots. However, later at a conference, when presenting her findings, she learned the hard way that you cannot just build an algorithm and decide if it is good or bad in complete isolation without considering how it integrates with the world it's embedded in. She also cites how some GPS systems used to be designed without taking into account the human-machine interface, leading to people blindly following directions that sometimes led them off cliffs or into the ocean.

00:15:00
In this section, Hannah Fry discusses the role of algorithms in decision-making, particularly in the field of medicine. She explains that while the first generation of algorithms in medicine was designed to answer simple "yes or no" questions, they were problematic due to their sensitivity and tendency to make mistakes. The second generation of algorithms involves agents that highlight areas of interest in images, which can then be labeled by a second algorithm, making it possible for pathologists and radiologists to interrogate the image. However, the third generation of algorithms in medicine is much harder challenging because it involves identifying which cancerous cells are actually dangerous and require treatment and which are not. Fry notes the potential danger of relying too much on algorithms to detect these cells, as it may lead to over-diagnosis and unnecessary treatment.

00:20:00
In this section, the conversation explores the challenges of algorithm transparency and proposes potential solutions. While it's easy to identify problems with algorithms that are not open source, making them open source is not a complete solution as it can create a hurdle for innovation. To address the problem, some suggest creating a separate regulatory board, similar to the FDA, that can stress test and verify the algorithms. However, there are no easy answers, and there will continue to be a need to evaluate when to use algorithms and when to rely on humans. Some circumstances require machines to be involved, while in others, it's better to keep humans away from the process.

00:25:00
In this section, Hannah Fry discusses the limitations and risks of relying on algorithms to make decisions. She describes a case where an algorithm was used in a court case and recommended a sentence based on the defendant's age and criminal history, but failed to consider other factors. The judge followed the algorithm's recommendation, resulting in an excessive sentence. Fry believes that while algorithms can assist with decision-making, they must be used with caution and humans must still be involved in the process. She also highlights the importance of designing interfaces and systems that prevent people from blindly following algorithmic recommendations and shirking responsibility. Finally, Fry notes that algorithms can improve decision-making in the judicial system, which is prone to inconsistency and subjectivity.

00:30:00
In this section, the importance of math and data in making clear decisions during the Covid-19 pandemic is discussed. Without pharmaceutical interventions or a vaccine, the data and numbers are the only things guiding decision-making and strategizing. Math has been used to predict what is coming next and drive government policies. A problematic issue was that not everyone understood non-linear and exponential functions, which caused some to take the pandemic less seriously. However, creating a mobile app that tracked people's movements and contacts has provided incredibly detailed data, making an enormous difference in the accuracy of predicting outcomes. This situation demonstrates the crucial role of math in winning a war with nature.

00:35:00
In this section of the transcript, mathematician Hannah Fry explains the concept of exponential growth and how it can be counterintuitive, using the classic example of the rice on the chessboard story. She also shares a unique angle to the famous Kasparov vs Deep Blue chess match, revealing that the machine was also playing psychological tricks on Kasparov, who was a "tornado" of a player with his own tricks. Fry's first book, "The Mathematics of Love," explores the use of math in human relationships, and she believes that understanding mathematical concepts can be helpful in romantic situations.

00:40:00
be that what Gottman and Murray have done with this research is to give us insight into how our arguments evolve over time. They have created equations that show the dynamics of arguments and hidden within those equations is a negativity threshold, which is essentially how annoying someone has to be before they provoke an extreme response in their partner. Using math in this way could help couples argue better and ultimately have better communication overall.

00:45:00
In this section, it is revealed that the couples with the best chance at long term success are actually those who have really low negativity thresholds. This means that if something annoys them, they speak up about it immediately and resolve the issue, rather than bottling it up and risking a blowout later on. By repairing and resolving very small issues in the relationship, the couples are able to avoid major conflicts later on and build a stronger foundation of security and comfort. The key is to use language that is helpful and not damaging when bringing up these issues.

