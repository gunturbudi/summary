# Summary of Jay McClelland: Neural Networks and the Emergence of Cognition | Lex Fridman Podcast #222

In the video, Jay McClelland discusses the role of neural networks in the development of cognition. He talks about how cognitive psychology at the time believed that understanding the neural structure of the brain would not lead to understanding the mind, but neural networks showed that this was not the case. McClelland credits the intuition he had about the importance of neural networks to his early training in cognitive psychology.
In this podcast, Jay McClelland discusses the work he's done on neural networks and the emergence of cognition. He talks about how cognitive development is not monolithic, and how the concept of learning should be approached in terms of connection weights. McClelland also discusses the work of Jeff Hinton in deep learning, and how gradient descent can be used to learn patterns.
In this podcast, Jay McClelland discusses his journey from being a musician to becoming a cognitive psychologist and researcher in neural networks and artificial intelligence. He shares his thoughts on the importance of neuroscience and remaining open to new ideas, as well as his work on the concept of "emergence."

Detail Summary: 
00:00:00
Jay McClelland discusses the history of neural networks and their role in the development of cognition. He notes that, while cognitive psychology at the time believed that understanding the neural structure of the brain would not lead to understanding the mind, neural networks showed that this was not the case. McClelland credits the intuition he had about the importance of neural networks to his early training in cognitive psychology.

00:05:00
Jay McClelland discusses the origins of cognition, how Darwin's theories led to his nightmares about the complexity of the human experience, and how neuroscience has helped to understand the process of brain development.

00:10:00
Jay McClelland discusses the continuity between humans and other animals, and how one special event - the origin of life - led to the development of human intelligence. He also discusses the concept of punctuated equilibrium, which is a theory that suggests that there are periods of stasis, followed by sudden changes in evolution.

00:15:00
Jay McClelland discusses his experiences in the early days of neural networks research, which led to the development of his books Parallel Distributed Processing and Explorations in Cognition. He recalls how a book by David Rumelhart and Ronald Hart called "Explorations in Cognition" inspired him to become more interested in cognitive science and join the community of cognitive scientists. McClelland credits Don Norman's "lightness" to the book and notes that Don Norman's "spirit of playful exploration of ideas" has always been an important part of his research.

00:20:00
Jay McClelland discusses the origins of neural networks, how they simulated neurons, and how they influenced the development of cognition. He also mentions Ronald Hart, one of the pioneers of neural networks, and Jeff Hinton, who is considered one of the fathers of deep learning.

00:25:00
Jay McClelland discusses the concept of neural networks and how they can help to explain the emergence of cognition. He also discusses how deep learning networks are becoming more and more powerful and how they could be used to classify images, recognize objects, and more.

00:30:00
Jay McClelland discusses his work with neural networks and the development of cognition. He talks about Dave Rommohart, one of the pioneers of mathematical psychology, and his strong academic record at Stanford. McClelland later became an assistant professor at University of California, San Diego, where he worked with Reunhard Plaut.

00:35:00
Jay McClelland's "Interactive Model of Reading" paper proposes an interactive model of reading in which every aspect of our interpretation of what is coming off the page depends on all the other levels of analysis.

00:40:00
Jay McClelland explains how hierarchical structures in neural networks can lead to the emergence of cognition, based on work he and a colleague did on the Interactive Activation Model of Letter Perception.

00:45:00
Jay McClelland describes the layers of neurons in the brain and how they get numbered as they become more abstract. He also talks about how connectionism is powerful but also has a building of knowledge problem. He says that from the emergence side, which is looking at how the layers work together to create cognition, he places himself on the radical eliminative connectionist perspective because he doesn't want people to think that he wants to build anything into the machine.

00:50:00
Jay McClelland discusses how the idea that higher level aspects of cognition are real, but not existing as such, can be applied to neural networks and the emergence of cognition. He also discusses how, in his opinion, the role of magic should be appreciated in the creation of illusions.

00:55:00
Jay McClelland discusses how he worked closely with Dave Heart and how Heart's death was a poignant and relevant tragedy to the discussion. McClelland's colleague Carolyn Patterson developed a test to measure semantic dementia. The patient loses the ability to differentiate similar breeds of animals, remember words, and relate concepts to each other.

01:00:00
Jay McClelland discusses how neural networks can help to model the process of cognition, as well as how Alzheimer's disease can affect this process.

01:05:00
Jay McClelland discusses how neural networks and the process of cognitive development are not monolithic, but instead involve a graded series of competencies with partial competencies still existing in the absence of other aspects. He also talks about how the concept of learning should be approached in terms of adjusting connection weights to solve a problem. Francis Crick and other scientists who were part of the PDP research group were amazed by the depth of McClelland's understanding of the brain, and he credits Hinton for inspiring him to think in this way.

01:10:00
Jay McClelland explains how gradient descent in neural networks can be used to learn patterns, and how Jeff Hinton's work on backpropagation led to the development of deep learning.

01:15:00
Jay McClelland's work on neural networks has had a profound impact on the field of cognitive science, and he has also been influential in the development of deep learning. His approach to problem solving is creative and intuitive, and he has a deep understanding of the mathematics underlying cognitive processes. Jeff Hinton is another cognitive scientist who has had a significant impact on neural networks and deep learning, and he has a strong visual aesthetic that helps him to understand complex concepts. Jim Keller is an experienced chip designer who has been able to improve his work by thinking in a unique way.

01:20:00
Jay McClelland discusses the work he's done on neural networks and the emergence of cognition, and how this field is continuing to grow in complexity. He also talks about his work in modeling mathematical cognition, and how mathematics is still being beaten by humans despite the advantages a computer intelligence may have.

01:25:00
Jay McClelland discusses how mathematics can be used to explore idealized worlds, and how this applies to real-world situations. He also discusses how mathematics allows for precise predictions about physical events, such as how many sheep someone has.

01:30:00
Jay McClelland discusses how mathematical reasoning is based on intuitive connections between ideas, and how this allows for breakthroughs in mathematics. He also quotes a quotation from a state park bench about the importance of intuition in mathematics.

01:35:00
Jay McClelland discusses how deep learning systems can generate creative solutions based on massive amounts of text data. He also discusses how mathematicians and logicians have developed formal systems to think about cognition.

01:40:00
Jay McClelland discusses the importance of intuition and formal learning in the development of cognition. He also discusses the difference between mathematical cognition and linguistic cognition. Lila Gleitman, who was trained in the same linguistics department as Chomsky, discovered that the intuitions of linguists went further than the intuitions of mathematicians.

01:45:00
Jay McClelland explains that formally trained academics have a mode of engagement with experience that is more structured and organized around systematicity and ability to conform with principles of a system than an ordinary person. He believes this difference is why it is difficult for them to introspect and understand their own beliefs.

01:50:00
Jay McClelland discusses how the natural numbers are a cultural construction and how we think differently depending on how much we have studied a subject.

01:55:00
Jay McClelland discusses the idea of cognitive constraints and how they can lead to the rationalization of after-the-fact reasons for decisions and actions. He goes on to say that this is something that we ought to be more cognizant of as human beings, as our own insight into why we hold the beliefs we do is not something that we totally control or totally observe. McClelland advises young people to find something that they are intrinsically motivated to engage with and to celebrate that discovery.

02:00:00
Jay McClelland shares how he stumbled into intrinsic motivation through accidents of his early morning classes in physics and psychology, and how it hooked him. He shares how being attentive to intrinsic motivation leads to an appreciation for the joys in life, such as tabular data. He recommends that individuals pursue what engages them intrinsically and stay with it for a while to see where it takes them.

02:05:00
Jay McClelland discusses his experiences as a musician and how they've influenced his work in psychiatry and neural networks. He shares his disillusionment with psychiatry as a field, and how he eventually found his passion in computer science.

02:10:00
Jay McClelland discusses how he lost faith in the psychiatric field after being disillusioned by its lack of progress in curing schizophrenia. He eventually found his path in cognitive psychology, which he feels is more in line with the philosophical interests he had when he was first interested in the human mind.

02:15:00
Jay McClelland discusses the importance of neuroscience and how it can help us better understand cognition, mortality, and our ability to be cognizant of it. He also comments on the importance of mathematical cognition.

02:20:00
Jay McClelland discusses the importance of remaining open to new ideas and the joy of scientific progress. He shares the story of how his dissertation project was rejected because it included theoretical ideas.

02:25:00
Jay McClelland discusses how he became interested in the study of cognition, how his work on neural networks led to his current research in symbolic artificial intelligence, and how meaning is created through collaborative effort.

02:30:00
Jay McClelland discusses the idea of "emergence," which is a process that occurs over time and is defined by its local context. He explains that in order to understand emergence, one must look at how stories are created and how they evolve over time. McClelland speaks about how curiosity is important for scientists, and how research that is driven by excitement is more likely to produce real breakthroughs.

