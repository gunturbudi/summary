# Summary of Dileep George: Brain-Inspired AI | Lex Fridman Podcast #115

Dileep George discusses the difficulties of trying to create an artificial intelligence using only neuroscience, and the need to use computational models in order to understand how the brain works. He also discusses the RCN architecture, which is a type of neural network that is designed to be efficient in inference.
This video discusses Dileep George's brain-inspired artificial intelligence model, which is able to correctly classify images as either an "a" or "not an a" using a limited number of examples. The model achieves this accuracy by recognizing general patterns in the image, and then extrapolating from there.
Dileep George is a computer scientist and professor at UC Berkeley who is working on developing brain-inspired artificial intelligence. In this video, he discusses the importance of understanding how the brain works in order to create artificial intelligence that is as accurate as the human brain.

Detail Summary: 
00:00:00
The Leap George is a researcher at the intersection of neuroscience and artificial intelligence, and co-founder of Vicarius with Scott Phoenix and formerly co-founder of Numenta with Jeff Hawkins. He discusses the brain-inspired AI research he's been involved in, and how understanding the principles underlying human intelligence may be more useful for engineering intelligence than any idea in mathematics, computer science, physics, or scientific fields outside of biology. His talk is also sponsored by Babel, Raycon Earbuds, and Masterclass.

00:05:00
The Blue Brain Project is an effort to build a brain without understanding it, by simulating it as a cat brain. However, if the simulation does not match the expected behavior, then the developers must "debug" it. While the models are detailed, they are still insufficient for understanding how the brain works at the individual neuron level.

00:10:00
The video discusses the difficulties of trying to create an artificial intelligence using only neuroscience, and the need to use computational models in order to understand how the brain works.

00:15:00
Dileep George discusses how understanding the brain would be to basically say look at the insights neuroscientists have found, understand that from a computational angle information processing angle build models using that, and then building the model which functions which is a functional model which is doing the task that we want the model to do it is not just trying to model a phenomena in the brain, it is trying to do what the brain is trying to do on the whole functional level.

00:20:00
Dileep George discusses the object recognition pathway in the brain, describing the layer-by-layer organization, the connections between layers, and the dynamics of the feedback connections. This information is fascinating and helps to explain some illusions, such as the kanetsa triangle.

00:25:00
Inference occurs when a model of the world is used to explain evidence from the world. This process includes projecting the model onto the evidence and taking the evidence back into the model to make a decision.

00:30:00
The video discusses how the brain processes information, and how concepts are encoded in cortical microcircuits. It suggests that the knowledge about these concepts is stored in the cortical columns, and that the neurons in these columns implement computations needed for inference.

00:35:00
The paper focuses on the role of feedback connections within the visual cortex model, as well as the need for a system to be compatible with other systems within the brain, in order to be able to understand complex concepts.

00:40:00
The video discusses the brain-inspired artificial intelligence (AI) model, which is based on the understanding that the human brain has a generative network that is top-down controllable.

00:45:00
The video discusses the "RCN" (Recursive cortical network) architecture, which is a type of neural network that is designed to be efficient in inference. The RCN is similar to a convolutional neural network in that it has a feed-forward pathway, feature detectors, and pooling. However, the RCN also has lateral connections between nodes that enforce compatibility between them, which helps to speed up inference.

00:50:00
In this video, Dileep George discusses how human perception differs from machine perception and how deep learning can still not achieve human-level performance on captchas.

00:55:00
Dileep George explains how the central problem in artificial intelligence is being able to reliably detect all the variations of the letter a. He goes on to say that the solution is to use an "RCN architecture" which helps us to reason in a more efficient way.

01:00:00
This video discusses Dileep George's brain-inspired artificial intelligence model, which is able to correctly classify images as either an "a" or "not an a" using a limited number of examples. The model achieves this accuracy by recognizing general patterns in the image, and then extrapolating from there.

01:05:00
Dileep George discusses how his brain-inspired artificial intelligence model is better than other systems available at that time, and discusses the criticism his work has received. He insists that the ideas in his paper are sound, and that it is important to have skepticism in the scientific community, but also believes that science is important and necessary.

01:10:00
The video discusses the idea that there is value to be found in brain-inspired AI, and that this value will be with us for some time. It also discusses the use of convolutional neural networks, which are not found in the brain, but are a helpful engineering trick.

01:15:00
Dileep George discusses the differences between brain-inspired AI and traditional AI, highlighting the importance of understanding the principles behind the processing. He also discusses his work in joint research with Jeff Hawkins on hierarchical temporal memory.

01:20:00
This video discusses the idea of "concepts" being pre-language, and how they are different than simple associations. It goes on to discuss a project that is attempting to build a cognitive program by extracting concepts from text.

01:25:00
The video discusses the idea that language is simulation control, and that the perceptual and motor systems are responsible for building a simulation of the world. The concepts of perceptual system, schema networks, concept learning, and language are all discussed.

01:30:00
Dileep George, a computer scientist, discusses his newly-released 175 billion parameter language model. He believes that it has potential to allow for reasoning and meaning in natural language, but notes that it still has limitations.

01:35:00
The video discusses the limitations of text as a source of information compared to the richness and interactivity of the physical world. It also discusses the potential of neural networks to capture and understand complex concepts and relationships.

01:40:00
The video discusses the idea that intelligence and reasoning can be modeled in poetic ways as connections and messages passing over a brain-inspired AI. It also discusses how episodic memories need to be stored as streams of pointers in the hippocampus, and how the cortex is needed to replay those memories. The video mentions that it is possible to put many structures into neural networks, and that graph neural networks are starting to emerge between them.

01:45:00
Dileep George discusses the potential applications of brain computer interfaces, discussing ways in which they could help people with disabilities, as well as advancing the level of communication between the brain and computer. While the technology is still in its early stages, it is an exciting prospect with many potential applications.

01:50:00
This video discusses Dileep George's work on brain-inspired artificial intelligence, which involves modeling the world and internalizing external actions. George discusses the importance of goals and motivation, and explains how they are different from mortality. He also discusses the idea of self-awareness, which is tied to the ability to suffer.

01:55:00
The video discusses the impact of books on brain-inspired artificial intelligence researcher Dileep George. George mentions Probabilistic Reasoning in Intelligent Systems by Judy Apple and The Mind's Eye by Doug Huffstetler as two books that had a significant impact on him.

02:00:00
Dileep George discusses the three books he recommends for people interested in artificial intelligence. He advises readers to be experimentalists and to pursue a field that is aligned with their interests and strengths.

02:05:00
Dileep George, a Redwood Neuroscience Institute workshop presenter, discusses the common undergraduate major of electrical engineering. He believes it has some of the right ingredients for a successful understanding of the brain, and that everyone should learn to program. He ends the talk with a quote from Marcus Aurelius, reminding the audience that they have power over their own minds and can achieve whatever they set their minds to.

02:10:00
The video features Dileep George, a computer scientist and professor at UC Berkeley, discussing his work in developing brain-inspired artificial intelligence. George discusses the importance of understanding how the brain works in order to create artificial intelligence that is as accurate as the human brain.

