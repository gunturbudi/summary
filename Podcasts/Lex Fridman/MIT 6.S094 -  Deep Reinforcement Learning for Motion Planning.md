# Summary of MIT 6.S094: Deep Reinforcement Learning for Motion Planning

Deep reinforcement learning is a machine learning technique that allows a computer to learn how to perform a task by observing positive and negative feedbacks. In this video, the basics of a neural network are explained, including the hidden layer and the forward pass. The loss function is discussed, and gradient descent is used to optimize it. The importance of stochasticity is also mentioned.
This video describes how to use deep reinforcement learning to train a neural network to autonomously plan movement in a simulated environment. The video provides an overview of the ConvNet.JS toolset, describes the types of inputs and outputs available, and provides an example of how to create a network and train it using the toolset. The video then discusses how to visualize the training process and show how the network has learned to plan movement in a simulated environment.

Detail Summary: 
00:00:00
This video introduces the DeepTraffic project, which is a machine learning competition using deep reinforcement learning. The first tutorial discusses the supervised learning process, which begins with acquiring data and ground truth, and ends with training a machine learning model. The tutorial also discusses semi-supervised learning, which uses a small amount of ground truth to train a machine learning model.

00:05:00
In this video, the MIT 6.S094 class covers neural networks and how they can be used to solve problems such as motion planning. The main computational building block of a neural network is a neuron, and a perceptron is a type of neuron that can approximate a NAND gate. This function can be learned by a neural network, which is demonstrated by showing how a perceptron can solve the NAND gate problem.

00:10:00
In this video, MIT professor Dr. Yoshua Bengio discusses the deep reinforcement learning algorithm he designed, called deep reinforcement learning for motion planning. This algorithm is based on a neural network, and is able to learn arbitrary logical functions that a circuit of NAND gates can represent. Additionally, the output of the neural network is made smooth with an activation function, which allows the network to achieve better accuracy than a circuit of perceptrons. Finally, Bengio discusses the process of learning in neural networks, and how adjusting the weights gradually and testing the results is essential for success.

00:15:00
Deep reinforcement learning is a type of machine learning that allows a machine to learn from experience and improve its performance based on feedback. In this video, the basics of a neural network are explained, including the hidden layer and the forward pass. The loss function is discussed, and gradient descent is used to optimize it. The importance of stochasticity is also mentioned.

00:20:00
This video explains Deep reinforcement learning, or how a neural network can be trained to learn to operate in a specific environment, without knowing what a "reward" or "punishment" may be. The video also goes over how a human can achieve similar results using a decision process that is based on instantaneous rewards and punishments.

00:25:00
In this video, MIT professors discuss deep reinforcement learning algorithms for motion planning. These algorithms use a policy to determine the best action to take for a given state, and a model to predict the consequences of those actions. If the environment is deterministic, the policy is optimal. However, if the environment is not deterministic, the optimal policy may not be the best one for the agent.

00:30:00
In this video, we learn about deep reinforcement learning, which is a method for learning to make optimal decisions in the future based on past experiences. Q learning is an off-policy approach that uses an estimate of the optimal policy to update the evaluation of a state and action pair.

00:35:00
Reinforcement learning is a machine learning technique that allows a computer to learn how to perform a task by observing positive and negative feedbacks. The Deep Q-Learning algorithm is used to model the world in a simpler way, using pixels as input.

00:40:00
In this video, Professor Stuart Russell describes the complex interplay between Epsilon function and Q-Learning update in reinforcement learning. This allows for the agent to explore the world and try different actions, without preconceived notions of what is a good action. Representation is an important factor in reinforcement learning, and Professor Russell discusses how the more complex the model, the worse the Bellman Equation Update becomes, making it difficult to fine-tune the agent to a specific problem.

00:45:00
Deep reinforcement learning is a technique that allows a machine to learn to play a game better than a human. The Deep Q-Learning paper from 2013 showed that a deep neural network can estimate a Q-Function from raw pixels, which is better than a human at playing a number of games.

00:50:00
Deep reinforcement learning is used to learn how to act in a virtual environment, by adjusting the weights of a network based on the expected reward for a given action. This process is repeated, with different experiences being used to adjust the weights, until the network reaches a desired level of accuracy.

This video discusses the deep Q learning algorithm, which is used to train a network to act in a virtual environment. The algorithm is initialized with a set of weights and a random action value, and is then used to select an action based on the estimated reward. If the action is chosen, the network is then executed and the reward is observed. If the action is not chosen, the algorithm selects the best action based on the past experience of the network. Finally, the experience from the action is stored in the memory and the algorithm samples a random transition from the memory.

00:55:00
This video explains deep reinforcement learning, which is a form of artificial intelligence that can learn to do tasks without being explicitly programmed. The video shows how the MIT 6.S094 algorithm can learn to win games of Atari without being customized for the game, using just the pixels of the game as input. This algorithm has been improved recently, and is promising for general artificial intelligence applications such as driverless cars.

01:00:00
Deep reinforcement learning is used in a simulated world to achieve a high average speed on a highway full of cars. The agent's grid representation shows the state of the world, and the red car's current speed is shown as well as how many cars the agent has passed. The agent can change the simulation speed to see how different settings affect the outcome.

01:05:00
The video presents deep reinforcement learning for motion planning, which allows for a car to be controlled in a safe way by learning how to optimize its actions for future rewards. The video discusses the different elements involved in this process, including the safety system, the brain, and the reinforcement learning algorithm.

01:10:00
This video describes how deep reinforcement learning can be implemented in a browser using the JavaScript programming language. The video provides an overview of how the deep Q learning algorithm works, and demonstrates how to modify variables in the code to change the behaviour of the simulated car. Once the parameters are set, the video shows how to start the training process, and how to evaluate the progress of the training by viewing the average speed over time.

01:15:00
This video demonstrates how to train a neural network using Deep reinforcement learning. To train the network, you first press the "Run Training" button and it quickly learns based on the input and the information provided. Once the training is complete, you can see the results in the form of a leaderboard. If you want to try to beat the current average speed, you should train the network yourself.

01:20:00
This video describes the Deep Reinforcement Learning (DRL) technique of training a neural network to autonomously plan movement in a simulated environment. The video provides an overview of the ConvNet.JS toolset, describes the types of inputs and outputs available, and provides an example of how to create a network and train it using the toolset. The video then discusses how to visualize the training process and show how the network has learned to plan movement in a simulated environment. The video concludes with a discussion of the Deep Reinforcement Learning prize, which is currently in development.

01:25:00
This YouTube video explains how deep reinforcement learning can be used to plan motions in the real world. The network that is trained is constantly updated based on recent data, so it can more safely and efficiently plan motions. If you have any questions, feel free to come talk to the developers after the video.

