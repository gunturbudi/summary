# Summary of Melanie Mitchell: Concepts, Analogies, Common Sense & Future of AI | Lex Fridman Podcast #61

In this video, Melanie Mitchell discusses the various uses of the term "artificial intelligence," and explains that it can be difficult to define the term due to its many different definitions. She also discusses how the field of AI has continued to develop over the years, and how Herbert Simon and John McCarthy were important pioneers in the field.
In this video, Melanie Mitchell discusses the concepts of analogies, common sense, and future of AI with Lex Fridman. She argues that it is important to have different ideas about what is meant by "super intelligence," and that a real test of intelligence is a conversation. Mitchell also discusses the concept of reductionism, and how it can be harmful to a system's complexity.

Detail Summary: 
00:00:00
Professor Melanie Mitchell discusses the various uses of the term "artificial intelligence," and explains that it can be difficult to define the term due to its many different definitions. She also discusses how the field of AI has continued to develop over the years, and how Herbert Simon and John McCarthy were important pioneers in the field.

00:05:00
In this video, Melanie Mitchell discusses the idea of artificial general intelligence (AI), and how much work remains to be done before we can create machines that can think like humans. She also notes that while strong AI is the view that a machine is actually thinking, weak AI is AI that only simulates thinking or carries out intelligent processes. She believes that we are closer to having a better understanding of the line between narrow weak AI and strong AI than we are to having a perfect understanding of what intelligence is.

00:10:00
The speaker discusses some of the concepts that are behind the push towards artificial intelligence, such as the idea of understanding ourselves better. She also touches on the idea of human intelligence being something that is more than just a single thing, and how this might be a driving factor behind the development of AI. While the speaker doesn't think humans are the only intelligent species, she does think that we are on the forefront of understanding intelligence in a broader sense.

00:15:00
In this video, Melanie Mitchell discusses the concept of intelligence and its spectrum. She points out that intelligence can be found at various levels in hierarchies, and that the most complex and self-aware system is the human brain. She also discusses the history of artificial intelligence and its struggles in predicting the future. While we may not be able to predict everything with certainty, Mitchell believes that with more understanding of our own intelligence, we will be better at predicting the future.

00:20:00
Melanie Mitchell talks about the current state of AI, the challenges that remain, and her prediction that human level intelligence will not be achieved until around 100 years from now.

00:25:00
In this video, Melanie Mitchell discusses the different perspectives on AI and their impact on the future. She notes that there are those who believe that AI is already at human-level, and that deep learning will scale to this level. There is also a view that deep learning is just one module in a larger cognitive framework, and that unsupervised learning is key to achieving this. Mitchell also highlights the importance of developmental learning, intuitive physics, and teaching machines metaphysics.

00:30:00
According to Gary Marcus, there are three camps in the AI community: the yawn camp, the supervising-self camp, and the "engineers who are actually building systems" camp. Marcus argues that all camps are important and that developing concepts is essential to thinking intelligently. He also points out that copycat, developed thirty years ago, is a key tool in thinking intelligently.

00:35:00
The video discusses the concept of analogy, and how it is used in various ways in order to flexibly apply concepts to new situations. It also discusses the importance of formulating new concepts, and the role analogies play in that process.

00:40:00
The video discusses the concept of analogy and how it is used in cognition. It argues that analogy making is fundamental to cognition, and that all concepts are mental simulations. It discusses the difficulty of knowing exactly how many concepts are in someone's head, and the importance of understanding how concepts are interconnected.

00:45:00
The video discusses the vast capacity of artificial intelligence, its connection to the human brain, and the need for further research in order to build AI that is not limited by common sense.

00:50:00
The presenter discusses how the breakthroughs in AI will be in hardware and software, and how we currently don't need new computation paradigms. They hope that approaches like copycat or other cognitive architectures will help improve perception systems.

00:55:00
Melanie Mitchell discusses how analogies can be helpful in understanding complex concepts, and how deep learning approaches can help to automate this process. She also discusses how memory is important in deep learning and how machine learning can be critiqued at a fundamental level.

01:00:00
According to Melanie Mitchell, the learning approaches used in deep learning are limited, and future advancements in the field may require a more "dynamic perception."

01:05:00
Melanie Mitchell discusses the difficulties of teaching machines concepts and analogies, and the power of self-play in AI. She also discusses autonomous driving, which she views as a more difficult problem than people realize.

01:10:00
Melanie Mitchell discusses the future of AI, including the concept of edge cases and the long tail problem. She explains that current self-driving car vision systems have problems with obstacles and that current policies are designed to be exceptionally responsive to anything that could potentially be an obstacle. She also notes that Tesla's approach to autonomous driving is based largely on vision only, while other companies are using a combination of different sensors to improve accuracy.

01:15:00
The speaker discusses the concepts of active learning, state data pipelines, multitasking learning, and the trade-off between human intelligence and ability to drive autonomously. He notes that while autonomous vehicles will be safer than humans, they will not be completely autonomous for a long time.

01:20:00
Melanie Mitchell discusses the role of emotions and motivation in human level intelligence and argues that they are integral to the process.

01:25:00
The article argues that we need to have values aligned with the capabilities of super intelligent AI in order to prevent harmful side effects, and that this might come before we reach super intelligence. Yoshua Bengio agrees, writing that the problem is something that might come before we reach super intelligence, and that we need to be cautious about dismissing fundamental parts of what intelligence would take.

01:30:00
Melanie Mitchell discusses the concept of "intelligible intelligence" and how it relates to the future of AI. She believes that there are more pressing existential threats that we should be worried about, such as nuclear weapons, climate change, and poverty.

01:35:00
In this video, Melanie Mitchell discusses the concepts of analogies, common sense, and future of AI with Lex Fridman. She argues that it is important to have different ideas about what is meant by "super intelligence," and that a real test of intelligence is a conversation. Mitchell also discusses the concept of reductionism, and how it can be harmful to a system's complexity.

01:40:00
The Santa Fe Institute is a research center that was founded in 1984. It is located in Santa Fe, New Mexico, and focuses on the edge of chaos. Its founders were frustrated with the field of physics and wanted to work on big questions without being siloed. Over the years, the Institute has hosted workshops and grown into a Research Institute. Today, it remains on the edge of chaos, studying complex systems.

01:45:00
Melanie Mitchell discusses her work on the copycat project, which is a project aimed at studying how natural language works. She is also proud of her work on the project's predecessor, the blocks world project, which aimed to study how artificial intelligence works at a fundamental level.

01:50:00
The hosts discuss how concepts and analogies are important in AI, and Melanie Mitchell gives some insights about copycat, a computer program that can make analogies.

