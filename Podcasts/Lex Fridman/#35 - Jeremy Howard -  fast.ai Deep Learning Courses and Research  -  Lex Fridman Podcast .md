# Summary of Jeremy Howard: fast.ai Deep Learning Courses and Research | Lex Fridman Podcast #35

In this interview, Jeremy Howard discusses his work in programming languages, deep learning, and his motivation for starting Fast AI. He describes how deep learning can be used to improve medical care and argues that empowering domain experts is the most effective way to achieve this.
In this interview, Jeremy Howard discusses the importance of deep learning, how it can be used to solve societally important problems, and the need for data scientists to be aware of the implications of their work. He also shares his thoughts on Swift and Tensorflow, and discusses how teaching deep learning can help students understand the concepts better.

Detail Summary: 
00:00:00
Jeremy Howard is the founder of fast AI, a research institute focused on making deep learning more accessible. He is also a distinguished research scientist at the University of San Francisco, a former president of Kegel, and the top ranking competitor there. In this interview, Howard discusses his love for music and how it has shaped his life. He also describes his experience using different programming languages and explains their connection to access and excel.

00:05:00
Jeremy Howard discusses his work in programming languages, including his love for Delphi and his dislike for Pascal. He also talks about his work in APL, which he is not familiar with but is a main family of programming languages from the 50s-60s.

00:10:00
Jeremy Howard discusses the history and development of the programming language APL, which he describes as a tool for thought, and its two main branches, k and j. He also discusses Perl and Python, two popular languages that have replaced APL in the market. Howard notes that Python is less elegant but has better data science libraries.

00:15:00
Jeremy Howard discusses the benefits of fast, lightweight programming languages like Swift. He argues that these languages make it easier for researchers and practitioners to innovate and improve deep learning algorithms.

00:20:00
Jeremy Howard discusses the benefits of deep learning in medicine, and how fast AI could help to fill the gap in doctor supply. He also talks about the founding story of his previous startup, In Lytic, which focused on deep learning for medical diagnosis and treatment planning.

00:25:00
Jeremy Howard discusses the potential benefits of deep learning for medical care, noting that while the technology is still relatively new, it has the potential to automate many tasks currently performed by human experts. He predicts that it will take a while for the technology to reach its full potential, as the medical world is currently unprepared for its potential.

00:30:00
Jeremy Howard discusses the challenges of regulating data and how it parallels the challenges of regulating autonomous vehicles. He goes on to discuss how data can be used to improve deep learning results, and how little data is often necessary to achieve results.

00:35:00
Jeremy Howard discusses his motivations for starting Fast AI, which is designed to make deep learning more accessible to domain experts. He explains that although deep learning has reached a point of rapid adoption, there are still many areas where it can be improved. Howard believes that empowering domain experts is the most effective way to achieve this.

00:40:00
Jeremy Howard discusses the difference between theory and practice in deep learning, citing a lack of success in academia of practical applications of deep learning. He shares his experience of developing a successful transfer learning algorithm, GLM fit, and its publication in a top-tier computational linguistics conference.

00:45:00
Jeremy Howard teaches two courses on deep learning: "Practical Deep Learning for Coders" and "Cutting-Edge Tech Mining for Coders." In the "Don Benched" competition, Howard and a few students attempted to train a model as fast as possible using only publicly available data. They reached the top of the leaderboard in both time and money.

00:50:00
Jeremy Howard discusses how deep learning can be sped up using a single machine, how multi-GPU setups slow down the iteration process, and how deep learning will play a major role in the next twenty years.

00:55:00
Jeremy Howard discusses fast.ai's deep learning courses and research, showing that it is possible to train neural networks much faster and more accurately using a higher learning rate. He also discusses the importance of deep learning in academia and the lack of research in this area.

01:00:00
Jeremy Howard discusses how the future of deep learning may involve humans becoming less necessary in the development process, as computers can now learn and operate on their own.

01:05:00
Jeremy Howard discusses the advantages and disadvantages of different deep learning frameworks, and provides a brief overview of each. He concludes that while Theano, TensorFlow, and PI Torch are all great platforms, GCP is the best way to get started with deep learning.

01:10:00
Jeremy Howard, a researcher at fast.ai, discusses how their deep learning library works and how it is different from other libraries. Howard also shares his thoughts on Swift and Tensorflow, two popular programming languages.

01:15:00
Jeremy Howard discusses how teaching deep learning can help students understand the concepts better. He also mentions that there can be a lot of bottlenecks for people when trying to learn the material, with coding being one of the most important.

01:20:00
Jeremy Howard discusses the importance of training models and the importance of understanding the inputs and outputs of the models. He also discusses how to become an expert in deep learning.

01:25:00
Jeremy Howard discusses his experience and advice for creating and running successful startups, including the importance of being pragmatic and training your state to capital money as long as possible.

01:30:00
Jeremy Howard discusses how he became profitable from fast.ai deep learning courses and research after initially struggling to cover costs. He recommends using spaced repetition learning methods such as Anki to help improve memory retention.

01:35:00
Jeremy Howard discusses the benefits of spaced repetition learning, how he uses it to improve his Chinese skills, and his advice for others wanting to learn new things.

01:40:00
Jeremy Howard discusses the importance of deep learning, how it can be used to solve societally important problems, and the need for data scientists to be aware of the implications of their work.

