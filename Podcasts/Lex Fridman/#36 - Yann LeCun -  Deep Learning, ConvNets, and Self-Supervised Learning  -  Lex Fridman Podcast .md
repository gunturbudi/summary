# Summary of Yann LeCun: Deep Learning, ConvNets, and Self-Supervised Learning | Lex Fridman Podcast #36

In this video, Yann LeCun discusses deep learning, convnets, and self-supervised learning. He argues that deep learning is a powerful tool that can be used to achieve human-level intelligence. He also discusses the importance of active learning, which he believes is a key to furthering machine intelligence.
Yann LeCun discusses deep learning, ConvNets, and self-supervised learning with Lex Fridman. He argues that deep learning requires a model of the world, which can be hard to create without body input. He also notes that if creators of Sophia could change their marketing or behavior, it would be a good idea.

Detail Summary: 
00:00:00
The interviewer, Jana Kun, speaks with Yann Laocoon, a professor of New York University, about deep learning and its various applications. Laocoon discusses the flaws of HAL 9000, and suggests that the development of ethical systems for artificial intelligence will be a difficult task.

00:05:00
Yann LeCun discusses deep learning, convnets, and self-supervised learning. He notes that deep learning has overturned many longstanding assumptions in machine learning and AI, and that even more surprises are awaiting us as we continue to develop these technologies.

00:10:00
Yann LeCun, a professor of computer science at NYU, discusses deep learning, convolutional neural networks, and self-supervised learning. He argues that these concepts are all obvious paths to creating intelligent machines, and that learning is the automation of intelligence. He also discusses his ideas about reasoning, which are based on the idea that reasoning is a consequence of learning. Finally, he discusses the idea of a neural network that reasons or a system that is able to build knowledge however we think about reasoning. If these concepts are developed further, LeCun believes that we will be able to build a machine that is capable of reasoning.

00:15:00
In this video, Yann LeCun discusses deep learning, convnets, and self-supervised learning. He explains that a chain of reasoning is a process by which you can update your knowledge about the state of the world, and that there needs to be a form of recurrence in order to represent knowledge as containing Wikipedia. He also discusses the importance of knowledge acquisition and suggests that symbols be replaced by vectors.

00:20:00
Yann LeCun discusses the 10-year-old paper he co-authored with Leon Go that discusses how learning systems should be able to manipulate objects in the same space, and how this is similar to the idea of working memory. He also discusses how physicists don't believe in causality, and how deep learning may have lost faith in the 1990s because of this.

00:25:00
In this video, Yann LeCun discusses deep learning and self-supervised learning. He mentions that it was hard to make deep learning work in the early days, and that it was difficult to release code that was open source. LeCun also mentions that he and his colleagues developed a compiler for a lisp interpreter that could be used to train deep learning systems.

00:30:00
Yann LeCun discusses deep learning, convolutional neural networks, and self-supervised learning. He argues that benchmarks and practical application are necessary to test ideas and progress in the field.

00:35:00
In this video, Yann LeCun discusses deep learning, convnets, and self-supervised learning. He discusses how new ideas can push the field forward, and how establishing benchmarks is part of the process. He also discusses the concept of general intelligence, and how humans are able to learn in many domains.

00:40:00
Yann LeCun discusses the importance of deep learning, ConvNets, and self-supervised learning, and how they are all impressive examples of artificial intelligence.

00:45:00
Yann LeCun discusses deep learning, convolutional neural networks (CNNs), and self-supervised learning. He says that while these technologies have achieved some successes, there is much more to be done in order to achieve true human-level intelligence. LeCun also discusses how interactive environments are needed to help with the acquisition of knowledge.

00:50:00
In this video, Yann LeCun discusses deep learning, ConvNets, and self-supervised learning. He notes that while deep learning can be used to generate data effectively, it can also have limitations when it comes to predicting the outcomes of certain actions in the real world. He goes on to say that active learning, which involves having a machine ask for human help in order to improve its performance, is a promising avenue for furthering machine intelligence.

00:55:00
Yann LeCun discusses deep learning, convnets, and self-supervised learning. He argues that deep learning is a model of intuitive physics that tells us we know the car is going to fall, we know about gravity, and babies learn this at a very early age. He also discusses how model-based reinforcement learning works and how it can be applied to tasks such as Wikipedia learning. LeCun argues that active learning is not a big leap and is just a more efficient way of doing things that we are already doing.

01:00:00
In this video, Yann LeCun discusses deep learning and ConvNets. He also discusses how self-supervised learning works and how we might be able to create artificial general intelligence.

01:05:00
Yann LeCun discusses deep learning, convolutional neural networks, and self-supervised learning with Lex Fridman. LeCun argues that deep learning requires a model of the world, which can be hard to create without body input. He also notes that if creators of Sophia could change their marketing or behavior, it would be a good idea.

01:10:00
Yann LeCun discusses the importance of emotions in deep learning, ConvNets, and self-supervised learning. He argues that the final product of these technologies won't be without emotions, but that they are necessary for higher-level cognition.

01:15:00
In this video, Yann LeCun discusses deep learning, convolutional nets, and self-supervised learning. He explains how these technologies can be used to identify patterns in data and reason about the physical world. LeCun congratulates a returning award winner and discusses the importance of deep learning in current and future technology.

