# Summary of MIT 6.S094: Introduction to Deep Learning and Self-Driving Cars

This video introduces deep learning for self-driving cars, with a focus on Convolutional Neural Networks (CNNs). It discusses the various sensors used in autonomous cars and their various tasks. It also discusses the history of autonomous car development, focusing on the second DARPA Grand Challenge.
The video discusses various deep learning networks and how they can be used to generate text or steer a car. It explains that while the technology is still a work in progress, there are some potential risks associated with it.

Detail Summary: 
00:00:00
This video introduces deep learning for self-driving cars, with a focus on Convolutional Neural Networks (CNNs). The video explains how to train a neural network in your browser, and discusses the project "DeepTraffic" - a computer game where the player controls a car and tries to drive below the speed limit. If you want to win, you only need a Chrome browser.

00:05:00
In this lecture, Professor Demis Hassabis discusses the question of what makes humans special, and how artificial intelligence (AI) is approaching this question. He explains that AI can be divided into three categories: formal, expert, and trivial tasks. He then goes on to discuss deep learning, which is a type of AI that focuses on deep, comprehensive understanding of data.

00:10:00
The video discusses the various sensors used in autonomous cars and their various tasks. It also discusses the history of autonomous car development, focusing on the second DARPA Grand Challenge.

00:15:00
This video discusses the DARPA Urban Challenge and how one of the cars that finished was from MIT. The Google self-driving car is also discussed and it is explained how it uses incredibly accurate sensors to build a three dimensional map of the world, localize itself effectively in that world, and move about that world in a well-defined way. It is then explained that there is a question of whether the self-driving car is in the United States or not, with the conclusion being that it is in Tokyo.

00:20:00
Neural networks are computational building blocks of the brain that are inspired by the way neurons work in the human brain. Neural networks can be used as linear classifiers to identify patterns in data.

00:25:00
In this video, MIT professor Andrew Karpathy explains how deep learning can be used to play "pong" with near-perfect accuracy. The Policy Network, a deep learning system trained on a large number of data points, is used to make decisions about which paddle to move in order to prevent the other player from scoring. This process is nontrivial and takes about three days to train on a regular computer.

00:30:00
In this video, the presenter explains how deep learning enables machines to learn to perform tasks that would formerly be difficult or impossible for them, such as playing video games. Supervised learning is the process of using data to train a machine to recognize specific patterns, while unsupervised learning is the process of having no information about the output. The future of deep learning is largely dependent on supervised learning capabilities, as unsupervised learning has yet to produce significant breakthroughs.

00:35:00
The video discusses the drawbacks of deep neural networks, and how a human being would approach a game such as "pong". It explains that deep neural networks need big data, efficient learners, and good loss functions in order to be effective. The video then shows a recent result from OpenAI in which a neural network was able to learn to play the game of coast runners, without needing to complete it.

00:40:00
In this video, Chuckling discusses the recent advancements in deep learning, which include more efficient training methods and infrastructure in terms of software and hardware. He also mentions that there have been no breakthroughs in terms of actually achieving artificial intelligence, but that the advances in training methods and compute are key to achieving this goal.

00:45:00
This video introduces deep learning, a subset of machine learning that has recently gained capabilities due to advances in GPUs. The different layers in a neural network form a higher order representation of the input, which is helpful for tasks like image classification. However, it is still unclear why neural networks work well for some tasks and not others. To get neural networks to work well on larger scale data sets and for more generalized applications, it is important to carefully tune the parameters.

00:50:00
Deep learning has been able to achieve some impressive results in the field of image recognition and classification, most notably with the successful training of a deep neural network to correctly classify images as either cats or leopards.

00:55:00
Convolutional neural networks are used to achieve human-level performance in computer vision, by processing images past multiple layers of neurons that maintain spatial information. This allows the network to determine which object is shown in an image. Additionally, segmentation is used to chop off the end of an image and assign it to a specific object.

01:00:00
The video discusses various deep learning networks, including the Deep Residual Networks (VGG-19), which are particularly good at detecting objects in images. The recurrent neural networks (Char-RNNs) are also discussed, and are able to generate text that is grammatically correct and syntactically correct, even for Wikipedia articles.

01:05:00
This video discusses how deep learning can be used to generate accurate descriptions of images, as well as to steer a car around an image.

01:10:00
This video discusses the difficulties of driving and the various tasks that are difficult for autonomous robots to complete. One of the most difficult tasks is getting out of a car.

01:15:00
This YouTube video discusses how deep learning and self-driving cars are still a work in progress, with potential risks associated with being easily fooled by neural networks.

01:20:00
This 1-paragraph summary explains the main points of the video, which is about how neural networks are easily fooled and can be unreliable in the real world. This has led to a lot of excitement and pessimism around the potential of A.I., and underscores the importance of research in this area.

01:25:00
The video discusses the hype cycle for deep learning and the caution that should be taken when engaging in the technology. One example of caution is spoofing of the cameras, which is becoming more common as self-driving cars become more popular. The different libraries that can be used for deep learning are discussed, with TensorFlow being the most popular. Torch is used for low-level tinkering, Caffe for computer vision, and ConvNetJS for explaining the basic concept of neural networks. Finally, deep learning in the browser is discussed.

01:30:00
The video explains that deep learning is a type of machine learning that is able to learn complex patterns from data, and that while GPUs are necessary for some tasks, they are not necessary for most tasks. It shows how to use a library called Keras.js to build neural networks in the browser, and explains how to access the references mentioned in the presentation.

