# Summary of Vladimir Vapnik: Predicates, Invariants, and the Essence of Intelligence | Lex Fridman Podcast #71

In the second part of his conversation with Lex Fridman, Vladimir Vapnik discusses predicates, invariants, and the essence of intelligence. He explains that only a few predicates are very useful and that deep learning is a way to find good predicates. He argues that the amount of predicates necessary for general intelligence is small, and that deep learning is simpler than convolutional networks.
In this video, Vladimir Vapnik discusses how to find good functions by looking for examples that satisfy certain requirements. He explains that the reality is an abstract idea that can be applied to data. He also discusses how to create an admissible set of functions, and how to think about useful functions in terms of their ability to describe data sets.

Detail Summary: 
00:00:00
In the second part of his conversation with Lex Fridman, Vladimir Vapnik discusses the difference between engineering intelligence and the science of intelligence, and his book, "Morphology of the Folk Tale," which discusses 31 predicates that have a sequential structure and are used to explain human behavior in Russian folklore.

00:05:00
Vladimir Vapnik discusses predicates, invariants, and the essence of intelligence. He believes that understanding intelligence is more complex than simply being able to create useful things, and that predicates are a less important part of understanding behavior.

00:10:00
Vladimir Vapnik discusses predicate and invariants, explaining that invariants are a projection of an image's structure. He believes that there exist critics who can summarize the essence of images, and he draws a connection between Plato, Hegel, and Wigner.

00:15:00
In this video, Vladimir Vapnik explains that predicates, invariants, and the essence of intelligence are related. He says that symmetry is a universal concept that can have degrees of symmetry.

00:20:00
Vladimir Vapnik discusses the concept of convergence in functions, and discusses how strong and weak convergence affects the decision making process. He also discusses the importance of predicates and invariants in digit recognition, and how they can be used to improve the accuracy of the task.

00:25:00
Vladimir Vapnik discusses the concept of weak convergence and how it applies to the search for good predicates. He argues that there is an infinite number of good predicates, but only a small amount are useful for the kinds of things that happen in the world.

00:30:00
Vladimir Vapnik discusses predicates, invariants, and the essence of intelligence. He explains that only a few are very useful and good predicates, and that deep learning is a way to find good predicates. He argues that the amount of predicates necessary for general intelligence is small, and that deep learning is simpler than convolutional networks, which are reproducing Hilbert's Space.

00:35:00
Vladimir Vapnik discusses predicates, invariants, and the essence of intelligence. He explains that predicates are the building blocks of intelligence, and that invariants are important in order to create an admissible set of functions for a neural network. He notes that if each good predicate significantly reduces the set of admissible functions, then there will be few predicates that can achieve this.

00:40:00
In this video, Vladimir Vapnik discusses predicate concepts and how they can be used to find functions in a dataset. He also discusses how predicates can be general or specific, and how they can be used to create a good admissible set of functions. He also discusses how predicates can be used to understand stories and create units that resonate with the reader.

00:45:00
Vladimir Vapnik discusses predicates, invariants, and the essence of intelligence. He explains that it is important to find predicates that don't create invariants, and that can be discovered by contradictions in the existing theory. Neural networks can help in this process by reverse engineering the function to find the essence.

00:50:00
Vladimir Vapnik discusses the concepts of predicates, invariants, and the essence of intelligence, and Lex Fridman asks how difficult it is to create invariants that will solve problems in image understanding. Vapnik believes that it is doable because there is a challenge, and he suggests that a student concentrate on this work if they want to understand more about invariants.

00:55:00
Vladimir Vapnik discusses how predicate and invariant are essential to intelligence, and how understanding concepts like life and intelligence can be difficult. He also talks about how his work on handwritten recognition has led to further understanding of Plato's philosophy.

01:00:00
In this video, Vladimir Vapnik discusses how to find good functions by looking for examples that satisfy certain requirements. He explains that the reality is an abstract idea that can be applied to data. He also discusses how to create an admissible set of functions, and how to think about useful functions in terms of their ability to describe data sets.

01:05:00
Vladimir Vapnik discusses predicates, invariants, and the essence of intelligence. He argues that the discovery of good predicates is the basis of human intelligence, and that language is not essential to expressing ideas.

01:10:00
Vladimir Vapnik discusses predicates, invariants, and the essence of intelligence, and argues that predicates can be understood in terms of human interpretable principals. He suggests that if this is the case, then we can develop a theory of visual information that is not limited by our current understanding of symbols.

01:15:00
Vladimir Vapnik discusses the concept of universal convergence, which is the idea that all functions that are studied in statistics will eventually converge to a certain expectation. He also discusses the idea of weak convergence, which is the idea that some functions may not converge but will still produce good results for learning purposes. Finally, Vapnik discusses the concept of predicates, which are the building blocks of intelligence. He believes that intelligence will eventually have a closed-form solution, similar to that of mathematics.

01:20:00
Vladimir Vapnik discusses why radial basis function approximations may not be ideal for certain bounds and why intelligence will likely be composed of a mix of heuristics. He also discusses the idea of recurrence and how it may be essential for human reasoning.

01:25:00
Vladimir Vapnik discusses the role of philosophy in machine learning, and how it helps to understand the concepts behind the field. He talks about how symmetry can be found in various aspects of the field, and how it can be helpful in guiding the development of algorithms.

01:30:00
Vladimir Vapnik discusses predicates, invariants, and the essence of intelligence. He explains that to learn effectively, one must do challenging problems and analyze them. The example he gives is the duck story, in which a child is asked to explain why a duck is swimming. The child is only able to provide a weak explanation, which demonstrates the importance of analyzing problems to understand how they work.

01:35:00
Vladimir Vapnik discusses the concept of predicates, invariants, and the essence of intelligence. He notes that mortality is a topic of contemplation for him, and that there is something valuable to be gleaned from contemplating it. He then suggests that music can be a good entry point into exploring these abstract ideas, as it is intimately connected to both language and images. However, he warns that the task of understanding predicates and invariants is a daunting one, and that it is important to be constantly exploring new ideas in order to stay intellectually engaged.

01:40:00
Vladimir Vapnik discusses the predicate for mysterious existence, and how it is different for common people and very smart people. He also talks about the challenge of managing people, and how studying English language and English literature can help.

