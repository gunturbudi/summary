# Summary of Anca Dragan: Human-Robot Interaction and Reward Engineering | Lex Fridman Podcast #81

Anca Dragan discusses the problem of human-robot interaction, how it can be difficult to model human qualities, and how simulation can be used to help with this problem.
Anca Dragan discusses the field of human-robot interaction and reward engineering. She argues that humans are rational and have intentions, which can be modeled by artificial intelligence. Dragan also discusses the challenges of designing rewards for human-robot interaction and how to overcome them.

Detail Summary: 
00:00:00
Professor Anca Dragan discusses how she became interested in robotics and how it gradually evolved from focusing on the technical aspects of robotics to developing a more anthropomorphic view of robots. She talks about how Jeff, the Google self-driving car, made her realize that robots can be more than just machines that manipulates objects.

00:05:00
Anca Dragan talks about her favorite fictional robot, Wally, and how it has a special connection to her husband's proposal. She also describes how expressive robots are, and how they can evoke strong emotional responses in people.

00:10:00
Anca Dragan discusses the human-robot interaction problem and how it can be difficult to model human qualities. She also discusses a particular view of human-robot interaction which is focused on tasks that a robot can perform on its own.

00:15:00
The video discusses the concepts of human-robot interaction and reward engineering. First, the robot is no longer the only actor in the space, and humans must take actions as well. Next, different types of humans must be taken into account when designing a robot. Finally, the complexities of understanding humans must be taken into account when designing a robot, as they may not always make choices in a rational manner.

00:20:00
Anca Dragan discusses human-robot interaction, discussing how machines can help to understand and optimize human behavior, by acting in certain ways.

00:25:00
The author discusses the idea that humans may be rational under different assumptions than robots, and that behavioral economics should try to account for this. He discusses one example of this, which is the lunar lander.

00:30:00
The video discusses the problem of human-robot interaction, focusing on the need for robots to understand human behavior in order to predict and manipulate it. It also touches on the importance of domain-agnostic algorithms, and the need for researchers to focus on solving problems rather than restricting themselves to a single area of research.

00:35:00
The presenter discusses a study in which humans were asked to try to understand the goals and intentions of a robot, and how to optimize the robot's communication in order to be less confusing and more informative. They argue that this is an inevitable process, and that by understanding how humans interact with robots, companies can create more persuasive experiences for users.

00:40:00
The video discusses the human-robot interaction problem, and how humans and robots can interact in a way that is both safe and effective. It discusses the idea of 'underactuation,' or the fact that humans and robots have different degrees of control and that humans cannot fully control what the robot does. It also discusses the idea of 'human robot interaction poetry,' or the way that humans and robots interact in a way that is both safe and effective, but is often influenced by the other person's actions.

00:45:00
The video discusses the difficulty of autonomous driving and how humans can affect the difficulty. It discusses how humans can perceive things at slow speeds, and how highway speeds can be dangerous. The speaker concludes that it is irresponsible to not use lighter when driving.

00:50:00
The speaker discusses how difficult it is to engineer human-robot interaction, and how machine learning may be able to help solve this problem. They also mention how driverless cars are benefiting from this technology, and how the area of human-robot interaction is still evolving.

00:55:00
Anca Dragan discusses the role of learning in human-robot interaction, noting that while learning is inevitable, it is also difficult due to the need to model human beings and the world around them. She goes on to discuss the usefulness of simulation in this area.

01:00:00
Anca Dragan discusses the importance of anticipating human behavior and reward engineering in artificial intelligence. She believes that humans are rational and have intentions, which can be modeled by artificial intelligence. She also believes that artificial intelligence needs to be able to reason about common-sense concepts such as fear of death.

01:05:00
Anca Dragan explains that there are already relatively successful systems in place that use level two autonomy or semi-autonomous driving. She notes that from a technical perspective, adding something such as taking control and doing its thing can be difficult, but if the thing is trustworthy and the person is engaged, it can go to what is known as "off policy." She also points out that from a human factors perspective, the assumption that a person functions the same when they are the driver versus when they are an observer is questionable. However, she notes that from a practical perspective, if the system is designed correctly, the human can be energized and better at observing the situation.

01:10:00
The speaker discusses the challenges of designing rewards for human-robot interaction and how to overcome them. He points out that this is a human problem, not a robotics problem, and that it requires understanding the user's objectives and preferences.

01:15:00
Anca Dragan discusses the concept of "good hearts law," which is when a metric becomes irrelevant because people are optimizing for it instead of doing their job. She also discusses the concept of physical human robot interaction, which is when a human interacts with a robot in a way that communicates a reward. This can be problematic because the cost versus reward function may be incorrect or the robot may not be able to respond optimally.

01:20:00
The speaker discusses how human-robot interaction is often difficult to determinate, and how it is important to take into account the specific context in which a reward is given in order to optimize behavior. They also mention that the "Three Laws of Robotics" are a simplistic way of thinking about ethical robot behavior, and that more sophisticated mechanisms should be in place to adjust rewards as the robot evolves understanding of the person.

01:25:00
The video features Anca Dragan, a researcher in the field of human-robot interaction and reward engineering. She discusses the state of the field, and how humans make decisions based on their preferences. Dragan also discusses a book she read in high school that inspired her to pursue a career in AI and human-computer interaction. She talks about the importance of meditation and contemplation on mortality, and how it affects her approach to research. Dragan finishes the video by talking about her research and how it relates to the goal of achieving immortality.

01:30:00
Anca Dragan discusses the human-robot interaction and reward engineering field, noting that finitude is a fundamental part of human existence and that she's not religious, but believes in an afterlife. She reflects on how, even though she can't answer the question of what gives life purpose, she tries to spend time doing things that bring her joy. Finally, she talks about the meaning of life and how you can't really ask someone that question with a straight face.

01:35:00
Anca Dragan discusses the human-robot interaction and reward engineering in a Planetarium. She argues that humans are "just on this little planet" and that the vastness of the universe is "frustrating." She also reflects on the potential of artificial intelligence to increase our cognitive capacity, and discusses the meaning of life.

