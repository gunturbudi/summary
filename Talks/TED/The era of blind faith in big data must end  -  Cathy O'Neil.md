# Summary of The era of blind faith in big data must end | Cathy O'Neil

Cathy O'Neil explains in this video that blindly trusting big data, algorithms, and machine learning models is dangerous. She argues that algorithms don't make things fair, but automate biases and practices of our society. She gives examples of data laundering and "weapons of math destruction," which are algorithms that create private power for private interests. O'Neil emphasizes the importance of checking algorithms for fairness and introduces the concept of an algorithmic audit, which checks data integrity, accuracy, and the long-term effects of feedback loops. The free market won't solve the problem, she argues, and data scientists need to act as translators of ethical discussions, while non-data scientists should demand accountability for algorithmic decision-making. Ultimately, she concludes that the era of blind faith in big data must end.

Detail Summary: 
00:00:00
In this section, Cathy O'Neil discusses the use of algorithms in our daily lives and how they can sometimes be wrong. She argues that algorithms are opinions embedded in code and often marketed as objective, true and scientific for intimidation purposes. O'Neil gives the example of the "value-added model," a complex, secret algorithm used to evaluate teachers, which ended up being a random number generator. She also explains that algorithms can have deeply destructive effects with good intentions and highlights the case of Roger Ailes, the founder of Fox News, who was ousted due to sexual harassment complaints. If they replaced their hiring process with a machine-learning algorithm, it could become a problem.

00:05:00
In this section, Cathy O'Neil discusses the dangers of blindly trusting big data, algorithms, and machine learning models. She argues that algorithms don't make things fair but instead automate the biases and past practices of our society. O'Neil gives examples of data laundering and "weapons of math destruction," which are algorithms and models that are privatised for private interests, creating private power. O'Neil explains that the free market won't solve the problem, stating that we are all biased and unconsciously endorse our society's bigotry, highlighting sociologists' experiments showing that applications with black-sounding names have consistently been sent fewer job offers than white sounding names.

00:10:00
In this section, Cathy O'Neil emphasizes the importance of checking algorithms for fairness and introduces the concept of an algorithmic audit. She explains that biases can be injected into algorithms by choosing what data to collect and determining the definition of success. O'Neil suggests checking the algorithms for data integrity, accuracy, and the long-term effects of feedback loops. Additionally, data scientists are urged to act as translators of ethical discussions and not arbiters of truth, while non-data scientists are encouraged to demand accountability for algorithmic decision-making. Ultimately, she asserts that the era of blind faith in big data must come to an end.

