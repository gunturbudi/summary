# Summary of Why AI Is Incredibly Smart â€” and Shockingly Stupid | Yejin Choi | TED

Yejin Choi speaks about the incredible intelligence of large-scale language models, as well as their limitations, such as small mistakes and concerns about safety and sustainability. She argues that the development of common sense is vital in ensuring ethical decision-making and that blindly scaling up AI models and training them with raw web data is not effective due to misinformation and societal biases. Choi calls for innovation in AI data and algorithms to build systems that can reason with common sense knowledge and be taught directly with human norms and values. Additionally, she discusses the importance of transparency in AI development and the potential concerns of having extremely large models owned by only a select few, emphasizing the need for synthesis of ideas to move forward.

Detail Summary: 
00:00:00
In this section, the author discusses the power of artificial intelligence models, specifically language models, and their ability to demonstrate sparks of artificial general intelligence. Despite the fact that these models have shown incredible potential, they have also demonstrated small, silly mistakes, leading to concerns about their safety and sustainability. One of the challenges presented by these large-scale models is the concentration of power within a few tech companies and the lack of transparency and accessibility for researchers outside of these companies. The author argues that in order to make AI sustainable and humanistic, it is necessary to democratize and make it smaller, as well as to teach human norms and values.

00:05:00
In this section, Yejin Choi discusses the intelligence and limitations of AI, and argues that the development of common sense should be a top priority to ensure ethical decision-making. Common sense, which includes naive physics and folk psychology, is currently an elusive challenge in AI, but essential for ensuring that AI behaves in accordance with human values. Choi suggests that blindly scaling up AI models and training them with large amounts of data is not the most effective approach, as raw web data is fraught with misinformation and societal biases. Instead, she calls for innovation in AI data and algorithms to build systems that can learn and reason with common sense knowledge.

00:10:00
In this section, Yejin Choi discusses the importance of teaching AI common sense, norms, and values in order to ensure that it operates sustainably and humanistically. Choi criticizes the current approach of using large language models and argues that AI needs to be taught directly, through hypothesis-making and experimentation, much like how a child learns. She explains that her team is working on developing knowledge distillation algorithms and open, human-inspectable knowledge repositories, including commonsense knowledge graphs and moral norm repositories, to teach AI basic commonsense norms and morals. Ultimately, transparency is key in the development of AI, and the data used to teach AI needs to be open and publicly available.

00:15:00
In this section, Choi discusses the potential concerns of having extremely large AI models that are created and owned by only a select few individuals or organizations. She mentions that while advancements in deep neural networks will likely play a role in the future of AI, there may be a "Goldilocks Zone" of scale where the winning recipe for AI development lies. She emphasizes the importance of synthesis of ideas to address these concerns and move forward with the development of AI.

