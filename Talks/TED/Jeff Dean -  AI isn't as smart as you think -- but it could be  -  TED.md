# Summary of Jeff Dean: AI isn't as smart as you think -- but it could be | TED

Jeff Dean, lead of AI Research at Google, discusses the progress of AI development and the need for improvement in his TED Talk. He highlights the success of neural networks and the role of computational power in driving progress. However, he suggests that AI development needs to shift towards training multitask models, taking in different modes of data, and using sparsely activated models to enable more efficient processes. He emphasizes the importance of responsible AI development with principles such as fairness and interpretability to avoid unintended consequences. Overall, he sees the potential for AI to make a positive impact on society, but stresses the need for careful and thoughtful application.

Detail Summary: 
00:00:00
In this section, Jeff Dean, lead of AI Research at Google, discusses how AI has made tremendous progress in the last decade in areas like computer vision, speech recognition, and language translation. These developments have led to significant benefits for society, such as predicting natural disasters and diagnosing diseases. The two underlying components that have enabled this progress are neural networks and computational power. However, Dean believes that we're still doing several things wrong and need to re-evaluate how we approach AI development. He delves into the history of neural networks and how it took a million times more computing power than in 1990 to make them as successful as they are today.

00:05:00
In this section, Jeff Dean describes the early successes of neural networks and the hardware tailored to fit their computations. Despite these successes, Dean believes that AI is still doing many things wrong and highlights three key areas for improvement. Firstly, rather than training neural networks for a single task, Dean suggests training multitask models that could specialize in different areas. This would allow expertise to be leveraged in new tasks. Secondly, Dean suggests that models should take in different modalities of input data, such as text, images, and speech, and fuse them together. Lastly, instead of using dense models, Dean believes that sparsely activated models, which call upon the relevant pieces of the brain for different tasks, could be more useful in the development of future AI systems.

00:10:00
In this section, Jeff Dean discusses the potential of AI and how it could be a step forward in how we build AI systems. He talks about the need to train general-purpose models that can do thousands or millions of things instead of building thousands of separate models. He highlights the importance of responsible AI and how AI systems need to be built with fairness, interpretability, privacy, and security for all users in mind. Dean believes that AI has the potential to help billions of people, from advancing educational systems to tackling climate change. The grand challenge in AI is how to generalize from a set of tasks to new tasks, and he sees the potential of building systems that are infused with how to do thousands and millions of tasks, making it possible to teach them to do a new thing with relatively few examples.

00:15:00
In this section, Jeff Dean discusses the potential unintended consequences of AI and the importance of applying it in ways that are careful and thoughtful to avoid negative consequences. He emphasizes the need for a set of principles to consider potential AI applications and how to carefully train machine-learning models to better reflect the values we want the system to have. While his research group collaborates with other Google groups such as Ads, Search, and Maps, they also publish openly on topics such as fairness and interpretability of machine-learning models to ensure they are developed safely and responsibly. Dean notes that this is a crucial time to demonstrate that big tech companies are using AI to make a better future.

