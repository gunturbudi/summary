# Summary of Peter Donnelly: How stats fool juries

Statisticians can fool juries, warns Peter Donnelly, using the example of the tragic Sally Clark case. Clark's conviction was based on the statistical assumption that the probability of two sudden infant deaths in one family is independent. The statistician presented this assumption to a jury without verifying it empirically or considering other factors that could increase the chance of a second sudden infant death. Furthermore, the statistician's one in 73 million chance of Clark being innocent didn't account for the a priori probability of her guilt or innocence. Donnelly emphasizes how important it is to understand uncertainty and chance in an increasingly data-oriented world, especially since statistics underpin many areas of research in science, social science, medicine, and industry.

Detail Summary: 
00:00:00
In this section of the transcript, statistician Peter Donnelly starts his talk by jokingly explaining how difficult it is to explain what statisticians actually do. He goes on to discuss the importance of chance, randomness, and uncertainty in our world, and poses a question involving tossing coins and searching for certain patterns. The audience is divided into two halves - one searching for the pattern "head-tail-tail" and the other searching for "head-tail-head" - and are asked to count the number of throws it takes to make each pattern appear before averaging them.

00:05:00
In this section, statistician Peter Donnelly presents a simple mathematical problem in which two sets of data are compared to determine whether they are the same, bigger or smaller. Most people vote that the two sets of data are the same because they assume that there is no difference between seeing "head-tail-head" versus "head-tail-tail" in a set of coin tosses. However, Donnelly reveals that "head-tail-head" actually takes more tosses on average to achieve than "head-tail-tail" because the former overlaps itself, while the latter does not. Donnelly also mentions that his real passion is genetics and there are connections between his example and genetics research, which involves DNA sequencing and modern statistical techniques.

00:10:00
In this section, Donnelly explains how genetic studies like the HapMap Project and the Wellcome Trust-funded studies are crucial to understanding the genetics behind common human diseases such as diabetes and heart disease. He also discusses a scenario where a test for a rare disease, let's say HIV, is 99% accurate but still generates a significant number of false positives because of the low prevalence of the disease. He emphasizes that we need to weigh up the plausibility of competing explanations after testing positive. He also gives a real-life example from a celebrated case in Britain where an expert witness got the statistics horribly wrong in a trial leading to the tragic conviction of an innocent woman who lost two children to what was thought to be cot death.

00:15:00
In this section, Donnelly explains how statisticians can fool juries, using the example of a woman named Sally Clark whose conviction of killing her children was based on the statistical assumption that the probability of two sudden infant deaths in one family is independent. The statistician presented this assumption to a jury without verifying it empirically or considering that there might be environmental and genetic risk factors that could increase the chance of a second sudden infant death. Furthermore, the statistician's one in 73 million chance of Clark being innocent was a logical error that didn't account for the a priori probability of her guilt or innocence. Donnelly emphasizes how important it is to understand uncertainty and chance, especially as statistics underpin many areas of research in science, social science, medicine, and industry.

00:20:00
In this section, Peter Donnelly talks about how experts can influence juries, and how that can go wrong. He gives the example of an architect versus a pediatrician, explaining that it's important to understand where one's competence lies. Donnelly also touches on the important issue of misinterpreted evidence in the early days of DNA profiling, where forensic scientists would misrepresent evidence by taking numbers out of context. All of this leads to the problem of juries who are bad at reasoning when it comes to uncertainty, and how it's necessary to be aware of this, and work towards doing something about it.

