# Summary of What moral decisions should driverless cars make? | Iyad Rahwan

In his talk, Iyad Rahwan explores the ethical issues that arise when designing driverless cars that require trade-offs, such as swerving to save either pedestrians or the car's passenger. He highlights the importance of considering societal values and the need for regulation to minimize total harm. Rahwan also discusses the Moral Machine website, which generates random driverless car dilemmas to collect data on what trade-offs people are comfortable with, emphasizing that the regulation of driverless cars is not only a technological problem but a societal cooperation problem. Finally, the speaker suggests that society needs to work together to decide what trade-offs are acceptable, recognizing humanity as a whole.

Detail Summary: 
00:00:00
In this section, the speaker introduces the idea of driverless cars and how they can help eliminate human errors that cause traffic accidents, which result in a significant number of deaths globally. He then poses a hypothetical situation involving a possible accident where the driverless car may have to swerve, causing the death of either pedestrians or the car's passenger. The speaker highlights the importance of considering ethical issues when designing driverless cars that require trade-offs. Waiting for full safety is not a feasible solution since it would delay the adoption of technology that could save millions of lives. The speaker suggests surveying people's opinions on societal values to inform regulations and laws that reflect the public opinion on ethical issues that arise with driverless cars.

00:05:00
In this section, Rahwan discusses the social dilemma that arises when we ask people to choose between prioritizing their own safety or minimizing total harm in the context of driverless cars. He explains the tragedy of the commons and how it can manifest as a tragedy of the algorithmic commons in a world where cars may learn to prioritize their passengers' safety over pedestrians. Rahwan also explores the challenges of regulating driverless cars to minimize total harm and highlights the need for society to come together to decide what trade-offs we are comfortable with and to enforce those trade-offs.

00:10:00
In this section, the speaker talks about the use of the Moral Machine website, which generates random dilemmas involving driverless cars, to collect data on what trade-offs people are comfortable with regarding ethical considerations in autonomous cars. The website has helped people recognize the difficulty of making such choices and the regulators who will be responsible for implementing corresponding regulations. The speaker explains that the issue of regulating driverless cars is a societal cooperation problem, where it is essential to get society to agree on trade-offs they are comfortable with. Finally, the speaker suggests that the regulation of driverless cars is not only a technological problem but a societal cooperation problem, that recognizes humanity as a whole, as Isaac Asimov introduced in his zeroth law.

