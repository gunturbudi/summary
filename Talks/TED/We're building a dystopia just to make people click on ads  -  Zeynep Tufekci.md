# Summary of We're building a dystopia just to make people click on ads | Zeynep Tufekci

Zeynep Tufekci's talk "We're building a dystopia just to make people click on ads" sheds light on the manipulation and control of people that can be achieved through the use of artificial intelligence (AI) by those in power such as Facebook, Google, Amazon, and others. She explains how these companies use AI to capture and sell personal data and attention to advertisers to create an enormous scale of persuasion architectures that can influence and target people's phone screens. Tufekci argues that we must restructure how digital technology operates, creating AI that supports human goals and is constrained by human values, to build a digital economy where data and attention are not for sale to the highest-bidding authoritarian or demagogue.

Detail Summary: 
00:00:00
In this section, the speaker explains that people often have the wrong perception of artificial intelligence and its impact. The speaker explains that we should not fear what AI will do to us on its own but how it can be used by those in power to manipulate and control us. Companies like Facebook, Google, Amazon, Alibaba, and Tencent are using artificial intelligence to capture and sell personal data and attention to advertisers. The speaker explains that AI can be used to build persuasion architectures at the scale of billions and can be targeted, understood and deployed to all individualâ€™s phone screens, which is different from any physical world persuasion architecture created. Facebook's use of big data and machine learning means they have access to all your data: private messages, photos, and even things you typed and then deleted, making the use of artificial intelligence more complex than what we have perceived.

00:05:00
In this section, the speaker discusses how machine-learning algorithms purchase data from data brokers and process it to understand the characteristics of people. The issue is that we don't truly understand how these algorithms categorize people based on this data. The algorithms only work if there is an enormous amount of data, so they encourage deep surveillance of everyone that can lead to deep consequences. For example, these algorithms could detect a person's mood disorder from social media posts, infer that they are about to enter a manic phase and target them with ads to buy Vegas tickets. Furthermore, the algorithms on social media platforms like YouTube recommended white supremacist videos and conspiracy theories based on what people have previously watched.

00:10:00
In this section, the speaker discusses the manipulation of algorithms to keep viewers on websites longer with the ultimate goal of serving more ads. The speaker gives an example of how YouTube's algorithm entices viewers to keep watching videos by recommending increasingly "hardcore" content. She explains that these algorithms can be used in nefarious ways, such as targeting anti-Semitic content to audiences prone to receptive to such messages. The speaker then delves into how social media platforms can be used as a tool to mobilize or demobilize people from voting or taking political action, citing the example of the Trump campaign's use of Facebook dark posts to demobilize certain voters.

00:15:00
In this section, the speaker discusses how algorithms can infer personal details such as political views, intelligence, and even sexual orientation just from Facebook likes. She argues that this power granted to online platforms can enable them to manipulate and persuade individuals, ultimately driving them to engage with content that aligns with certain political beliefs. Furthermore, in countries like China, face detection technology has been leveraged by the state to identify and arrest individuals, highlighting the potential dangers of these technologies. The speaker warns that the infrastructure of surveillance authoritarianism is being built merely to get people to click on ads, and that we need to fundamentally change the structures and business models that underpin our digital platforms.

00:20:00
In this section, Zeynep Tufekci argues that the issue with Facebook is either that half a trillion dollar company is a con and ads don't really work, or that the company's power of influence is a major concern. She acknowledges that there is no simple recipe for changing the way in which digital technology operates, but emphasizes that we need to restructure it from the way technology is developed to the way the incentives, economic and otherwise, are built into the system. We must face issues such as the lack of transparency created by the proprietary algorithms, machine learning's opacity, and indiscriminate data being collected about us. The solution involves mobilizing our technology, creativity, and politics, to build AI that supports us in our human goals and is constrained by our human values. Ultimately, we need a digital economy where our data and attention are not for sale to the highest-bidding authoritarian or demagogue.

