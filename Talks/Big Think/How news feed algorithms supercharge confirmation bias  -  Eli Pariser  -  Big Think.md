# Summary of How news feed algorithms supercharge confirmation bias | Eli Pariser | Big Think

Source: https://youtube.com/watch?v=prx9bxzns3g

In "How news feed algorithms supercharge confirmation bias," Eli Pariser discusses the concept of the filter bubble and how algorithms create a personalized universe of information that can reinforce confirmation bias. Pariser suggests that algorithmically mediated media is different from traditional media because we don't know what basis the algorithm thinks we are, and it's often what's not shown to us that is most important. Furthermore, algorithms don't have a representative portrayal of who we are as human beings, and every list has some editorial viewpoint. Therefore, we need to take responsibility for the fact that powerful editors are shaping what we see and don't see without taking on the responsibility of that editorial judgment.

Detail Summary: 
00:00:00
In this section, Eli Pariser discusses the concept of the filter bubble, which is a personalized universe of information generated by algorithms trying to predict what an individual is interested in. He suggests that this algorithmically mediated media is different from traditional media because we don't know what basis the algorithm thinks we are, and it's often what's not shown to us that is most important. Furthermore, the data that algorithms have to base their decisions on is not a representative portrayal of the whole of who we are, as human beings, and every list has some editorial viewpoint about what matters and what doesn't. Therefore, we have to grapple with the fact that we have more powerful editors than ever before shaping what we see and don't see, without taking on the responsibility of that editorial judgment.

